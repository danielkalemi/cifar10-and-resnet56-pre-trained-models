{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CNN -CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUGvmm_yn1uo"
      },
      "source": [
        "# CS345 - CNN on CIFAR10 - Keras Functional Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2rBXa4jA_9L"
      },
      "source": [
        "\n",
        "# Preparation of Runtime environment\n",
        "Mount Google Drive and check that the proper folder exists under CS345"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2taBUomqJHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd620b0-2758-47d1-d586-d4d8498a363c"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "print(\"-\"*80)\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/Colab Notebooks/CS345/CS345_Project2\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "--------------------------------------------------------------------------------\n",
            "'CNN -CIFAR10.ipynb'   data  'Image Data.ipynb'   lib   models\t rx   testSet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5VGRuYMqh3x"
      },
      "source": [
        "## Begin of source code\n",
        "Use python to change the directory to the root folder of this project. This is required in order to import packages that are subfolders in the project.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzOzkeUppxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afebe6d1-dfb3-4e4c-c5bb-b1863d8ac5c4"
      },
      "source": [
        "import os\n",
        "\n",
        "# Change to this source code folder\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/CS345/CS345_Project2\")\n",
        "print(\"Current dir: \", os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current dir:  /content/gdrive/My Drive/Colab Notebooks/CS345/CS345_Project2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1uCq93lnzWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe61215-c610-4272-dcfd-8f7f5488d675"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from rx.visualization import CPlot\n",
        "from tensorflow import keras\n",
        "\n",
        "from data.cifar10 import CCIFAR10DataSet\n",
        "from lib import CEvaluator\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, Softmax\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# What tensorflow version is installed in this VM?\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOPt9O-7oHHa"
      },
      "source": [
        "Create the dataset object that loads all data into the memory. Create the one-hot vectors as targets for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiDspBvJoHOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28ca1df-02aa-4b00-9b4f-329ead7e5c12"
      },
      "source": [
        "# ... // Create the data objects \\\\ ...\n",
        "oDataset = CCIFAR10DataSet()\n",
        "\n",
        "# One hot encoding for the training and validation set labels\n",
        "nTSLabelsOnehot = keras.utils.to_categorical(oDataset.TSLabels)\n",
        "nVSLabelsOnehot = keras.utils.to_categorical(oDataset.VSLabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Download progress: 100.0%\n",
            "Download finished. Extracting files.\n",
            "Done.\n",
            "Classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59JtDsuqBl5i"
      },
      "source": [
        "Declare the class of the model that contains the architecture and functions needed to train it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmOtDjifBsZK"
      },
      "source": [
        "# =========================================================================================================================\n",
        "class CCNNSimple(object): \n",
        "  # --------------------------------------------------------------------------------------\n",
        "  def __init__(self, p_oInputShape=[32,32,3], p_nModuleCount=6, p_bHasBias=True):\n",
        "    # ................................................................\n",
        "    self.InputShape   = p_oInputShape\n",
        "    self.ModuleCount  = p_nModuleCount\n",
        "    self.HasBias      = p_bHasBias\n",
        "    self.Input        = None\n",
        "    self.Modules      = [None]*self.ModuleCount\n",
        "    self.Output       = None\n",
        "    self.OutputTensor = None\n",
        "    self.Model        = None\n",
        "    # ................................................................\n",
        "    self.DefineModel()\n",
        "  # --------------------------------------------------------------------------------------  \n",
        "  def DefineModel(self):\n",
        "\n",
        "    self.Input = Input(shape=self.InputShape) \n",
        "    tA = self.Input\n",
        "    \n",
        "    # // Module 1 \\\\\n",
        "    tA = Conv2D(96, kernel_size=3, strides=2, padding=\"same\",  \n",
        "                  kernel_initializer=\"glorot_uniform\", use_bias=self.HasBias, bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "    tA = MaxPooling2D(pool_size=[2, 2], strides=[1, 1], padding=\"same\")(tA) \n",
        "    tA = BatchNormalization()(tA)\n",
        "    \n",
        "    # // Module 2 \\\\\n",
        "    tA = Conv2D(256, kernel_size=3, strides=1, padding=\"same\",  \n",
        "                  kernel_initializer=\"glorot_uniform\", use_bias=self.HasBias, bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "    tA = MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=\"same\")(tA)\n",
        "    tA = BatchNormalization()(tA)\n",
        "\n",
        "    # // Module 3 \\\\\n",
        "    tA = Conv2D(384, kernel_size=3, strides=1, padding=\"same\",  \n",
        "                  kernel_initializer=\"glorot_uniform\", use_bias=self.HasBias, bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "    tA = BatchNormalization()(tA)\n",
        "\n",
        "    # // Module 4 \\\\\n",
        "    tA = Conv2D(384, kernel_size=3, strides=1, padding=\"same\",  \n",
        "                  kernel_initializer=\"glorot_uniform\", use_bias=self.HasBias, bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "    tA = BatchNormalization()(tA)\n",
        "\n",
        "    # // Module 5 \\\\\n",
        "    tA = Conv2D(256, kernel_size=3, strides=1, padding=\"same\",  \n",
        "                  kernel_initializer=\"glorot_uniform\", use_bias=self.HasBias, bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "    tA = MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding=\"same\")(tA) \n",
        "    tA = BatchNormalization()(tA)\n",
        "    \n",
        "\n",
        "    # // Module 6 - Classifier\\\\\n",
        "    tA = Flatten()(tA)\n",
        "    \n",
        "    tA = Dropout(0.5)(tA) \n",
        "    tA = Dense(1024, use_bias=self.HasBias, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "\n",
        "    tA = Dropout(0.5)(tA)\n",
        "    tA = Dense(1024, use_bias=self.HasBias, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\")(tA)\n",
        "    tA = Activation(\"relu\")(tA)\n",
        "\n",
        "    tA = Dense(10, use_bias=self.HasBias, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\")(tA)\n",
        "    tA = Softmax()(tA)\n",
        "\n",
        "    self.Output = tA\n",
        "    \n",
        "    self.Model = keras.Model(self.Input, self.Output, name=\"SimpleCNN\")\n",
        "  # --------------------------------------------------------------------------------------------------------\n",
        "  def LearningRate(self, p_nEpochNumber):\n",
        "    if p_nEpochNumber < 10:\n",
        "      nLR = 0.1\n",
        "    elif p_nEpochNumber < 20:\n",
        "      nLR = 0.01\n",
        "    else:\n",
        "      nLR = 0.001\n",
        "    return nLR\n",
        "  # --------------------------------------------------------------------------------------------------------\n",
        "# =========================================================================================================================    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTqePwJIpLoI"
      },
      "source": [
        "Recreate the model. Change and re-run this area of the code that contains all the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGbWO0s7B2a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a15b26-fc45-4e9e-f02f-344ff1f3a9ba"
      },
      "source": [
        "# _____ | Hyperparameters | ______\n",
        "# // Training \\\\\n",
        "MAX_EPOCH                   = 30;\n",
        "BATCH_SIZE                  = 128    \n",
        "LEARNING_RATE               = 1e-3;\n",
        "MOMENTUM                    = 0.9\n",
        "IS_ACCELERATED_MOMENTUM     = True\n",
        "\n",
        "sModelFileName = os.path.join(\"MLModels\", \"SimpleCNN.keras\")\n",
        "bMustTrain = not os.path.isfile(sModelFileName)\n",
        "\n",
        "# Train the model if not already trained\n",
        "if bMustTrain:\n",
        "  oCNNSimple = CCNNSimple(oDataset.ImageShape)\n",
        "  oCNNModel = oCNNSimple.Model\n",
        "  \n",
        "  oCostFunction = keras.losses.CategoricalCrossentropy()\n",
        "  oLRSchedule = keras.callbacks.LearningRateScheduler(oCNNSimple.LearningRate) \n",
        "  oOptimizer = keras.optimizers.SGD(learning_rate=0.0, momentum=MOMENTUM, nesterov=IS_ACCELERATED_MOMENTUM)   \n",
        "  oMetric = keras.metrics.CategoricalAccuracy(name=\"average_accuracy\", dtype=None)\n",
        "\n",
        "  oCNNModel.compile(loss=oCostFunction, optimizer=oOptimizer, metrics=oMetric)\n",
        "\n",
        "  oCNNModel.train_on_batch(oDataset.TSSamples[0:100, ...], nTSLabelsOnehot[0:100, :]) \n",
        "  oCNNModel.summary()\n",
        "else:\n",
        "  print(\"It is already trained!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"SimpleCNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 16, 16, 96)        2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       221440    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,582,410\n",
            "Trainable params: 8,579,658\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D-5cxL2CCif"
      },
      "source": [
        "Train the model and then save the model and training process state to disk. Alternatively load from disk a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gj_5a-MCM6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4785867d-941b-40be-f4d6-a61754681996"
      },
      "source": [
        "if bMustTrain:\n",
        "  # Train the model\n",
        "  oCNNModel.fit(oDataset.TSSamples, nTSLabelsOnehot, epochs=MAX_EPOCH, batch_size=BATCH_SIZE, callbacks=[oLRSchedule]\n",
        "                , verbose=1, validation_data=(oDataset.VSSamples, nVSLabelsOnehot))\n",
        "  if not os.path.exists(\"MLModels\"):\n",
        "    os.makedirs(\"MLModels\")\n",
        "\n",
        "  # Saving the state of the model (values of parameters) and the training process (internal values).\n",
        "  oCNNModel.save(sModelFileName, save_format=\"h5\") \n",
        "else:\n",
        "  # Load the state of the model and the training process\n",
        "  oCNNModel = keras.models.load_model(sModelFileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 19s 45ms/step - loss: 2.0108 - average_accuracy: 0.2981 - val_loss: 2.4396 - val_average_accuracy: 0.2585\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 1.4945 - average_accuracy: 0.4624 - val_loss: 1.3840 - val_average_accuracy: 0.4953\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 1.2357 - average_accuracy: 0.5598 - val_loss: 1.2797 - val_average_accuracy: 0.5294\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 1.0861 - average_accuracy: 0.6190 - val_loss: 1.0414 - val_average_accuracy: 0.6259\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.9662 - average_accuracy: 0.6627 - val_loss: 1.0434 - val_average_accuracy: 0.6447\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.8770 - average_accuracy: 0.6953 - val_loss: 1.1106 - val_average_accuracy: 0.6261\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.8002 - average_accuracy: 0.7260 - val_loss: 1.1644 - val_average_accuracy: 0.6182\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.7296 - average_accuracy: 0.7510 - val_loss: 1.2065 - val_average_accuracy: 0.5998\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.6732 - average_accuracy: 0.7710 - val_loss: 0.8090 - val_average_accuracy: 0.7244\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.6189 - average_accuracy: 0.7902 - val_loss: 0.9096 - val_average_accuracy: 0.6965\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.4536 - average_accuracy: 0.8440 - val_loss: 0.5679 - val_average_accuracy: 0.8098\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.3795 - average_accuracy: 0.8678 - val_loss: 0.5624 - val_average_accuracy: 0.8163\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.3441 - average_accuracy: 0.8803 - val_loss: 0.5654 - val_average_accuracy: 0.8182\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.3172 - average_accuracy: 0.8882 - val_loss: 0.5718 - val_average_accuracy: 0.8171\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.2972 - average_accuracy: 0.8960 - val_loss: 0.5674 - val_average_accuracy: 0.8208\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.2764 - average_accuracy: 0.9022 - val_loss: 0.5762 - val_average_accuracy: 0.8235\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.2566 - average_accuracy: 0.9103 - val_loss: 0.5940 - val_average_accuracy: 0.8225\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.2415 - average_accuracy: 0.9143 - val_loss: 0.5992 - val_average_accuracy: 0.8213\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.2210 - average_accuracy: 0.9225 - val_loss: 0.6262 - val_average_accuracy: 0.8210\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.2075 - average_accuracy: 0.9262 - val_loss: 0.6312 - val_average_accuracy: 0.8237\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1794 - average_accuracy: 0.9361 - val_loss: 0.6127 - val_average_accuracy: 0.8294\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1696 - average_accuracy: 0.9413 - val_loss: 0.6202 - val_average_accuracy: 0.8308\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1666 - average_accuracy: 0.9415 - val_loss: 0.6252 - val_average_accuracy: 0.8302\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1650 - average_accuracy: 0.9423 - val_loss: 0.6281 - val_average_accuracy: 0.8300\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1597 - average_accuracy: 0.9445 - val_loss: 0.6308 - val_average_accuracy: 0.8294\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1573 - average_accuracy: 0.9445 - val_loss: 0.6374 - val_average_accuracy: 0.8288\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1564 - average_accuracy: 0.9454 - val_loss: 0.6418 - val_average_accuracy: 0.8303\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1513 - average_accuracy: 0.9466 - val_loss: 0.6459 - val_average_accuracy: 0.8289\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1515 - average_accuracy: 0.9466 - val_loss: 0.6483 - val_average_accuracy: 0.8315\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 16s 41ms/step - loss: 0.1504 - average_accuracy: 0.9476 - val_loss: 0.6545 - val_average_accuracy: 0.8302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsO3yaEhCRrY"
      },
      "source": [
        "Recall the test samples through a trained model, get the predicted probabilities from the output neurons (softmax activation function) and the maximum out of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWCHGrYoCRbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355eb909-22f2-4de6-ca79-4e5d35d45cc3"
      },
      "source": [
        "# Predictions\n",
        "nPredictedClassProbabilities = oCNNModel.predict(oDataset.VSSamples)\n",
        "nPredictedClassLabels = np.argmax(nPredictedClassProbabilities, axis=1)\n",
        "\n",
        "print(nPredictedClassProbabilities.shape)\n",
        "print(nPredictedClassLabels.shape)\n",
        "print(\"\")\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True) # Pretty print numpy floating point numbers\n",
        "\n",
        "nTestSampleIndex = 0\n",
        "print(\"Ground Truth (one-hot):\", nVSLabelsOnehot[nTestSampleIndex,:])\n",
        "print(\"Predictions           :\", nPredictedClassProbabilities[nTestSampleIndex,:])\n",
        "print(\"\")\n",
        "\n",
        "nTestSampleClassLabel = oDataset.VSLabels[nTestSampleIndex]\n",
        "print(\"Probability for correct class %s is %.3f\" % (oDataset.ClassNames[nTestSampleClassLabel], nPredictedClassProbabilities[nTestSampleIndex, nTestSampleClassLabel]))\n",
        "nConfusingClassLabel = 5\n",
        "print(\"Probability for wrong   class %s is %.3f\" % (oDataset.ClassNames[nConfusingClassLabel], nPredictedClassProbabilities[nTestSampleIndex, nConfusingClassLabel]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "(10000,)\n",
            "\n",
            "Ground Truth (one-hot): [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "Predictions           : [0.001 0.001 0.005 0.907 0.003 0.024 0.056 0.001 0.001 0.002]\n",
            "\n",
            "Probability for correct class cat is 0.907\n",
            "Probability for wrong   class dog is 0.024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M3i8u9QCkhb"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Q1UpG9ClQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2876d8-8c18-4b13-8221-2f65987659fa"
      },
      "source": [
        "# Evaluation\n",
        "oEvaluator = CEvaluator(oDataset.VSLabels, nPredictedClassLabels)\n",
        "\n",
        "print(oEvaluator.ConfusionMatrix)\n",
        "for nIndex,sClassName in enumerate(oDataset.ClassNames):\n",
        "  print(\"|__ [%s]  Accuracy:%.4f | Precision:%.4f | F1 Score:%.4f\" % (sClassName.rjust(15, \" \"), oEvaluator.Recall[nIndex], oEvaluator.Precision[nIndex], oEvaluator.F1Score[nIndex]))\n",
        "\n",
        "print(\"Average Accuracy: %.4f\" % oEvaluator.AverageRecall)\n",
        "print(\"Average F1 Score: %.4f\" % oEvaluator.AverageF1Score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[865  14  29  15  11   2   5  11  32  16]\n",
            " [  8 906   2   8   3   1   4   0  18  50]\n",
            " [ 48   2 747  40  68  36  38  11   7   3]\n",
            " [ 14   4  45 704  51 104  37  25  10   6]\n",
            " [ 10   1  43  38 823  21  23  34   5   2]\n",
            " [  8   3  24 142  44 722  13  37   2   5]\n",
            " [  7   3  25  46  26   6 877   5   3   2]\n",
            " [  8   3  18  33  33  32   3 865   0   5]\n",
            " [ 36  11   6  14   1   1   4   3 910  14]\n",
            " [ 32  49   2   8   2   1   2   8  13 883]]\n",
            "|__ [       airplane]  Accuracy:0.8650 | Precision:0.8349 | F1 Score:0.8497\n",
            "|__ [     automobile]  Accuracy:0.9060 | Precision:0.9096 | F1 Score:0.9078\n",
            "|__ [           bird]  Accuracy:0.7470 | Precision:0.7938 | F1 Score:0.7697\n",
            "|__ [            cat]  Accuracy:0.7040 | Precision:0.6718 | F1 Score:0.6875\n",
            "|__ [           deer]  Accuracy:0.8230 | Precision:0.7750 | F1 Score:0.7983\n",
            "|__ [            dog]  Accuracy:0.7220 | Precision:0.7797 | F1 Score:0.7497\n",
            "|__ [           frog]  Accuracy:0.8770 | Precision:0.8718 | F1 Score:0.8744\n",
            "|__ [          horse]  Accuracy:0.8650 | Precision:0.8659 | F1 Score:0.8654\n",
            "|__ [           ship]  Accuracy:0.9100 | Precision:0.9100 | F1 Score:0.9100\n",
            "|__ [          truck]  Accuracy:0.8830 | Precision:0.8955 | F1 Score:0.8892\n",
            "Average Accuracy: 0.8302\n",
            "Average F1 Score: 0.8302\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}